# simple_char_recognizer_24x24_fixed.py
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import os
import random
import torchvision.transforms as transforms

# –ü—Ä–æ—Å—Ç–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
class Config:
    img_size = 24
    chars = '–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø' + \
            '–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è' + \
            '0123456789' + '.,:()'
    num_classes = len(chars)
    batch_size = 128
    epochs = 30
    learning_rate = 0.001

# –ü—Ä–æ—Å—Ç–æ–π –¥–∞—Ç–∞—Å–µ—Ç
class SimpleCharsDataset(Dataset):
    def __init__(self, num_samples=10000, is_train=True):
        self.num_samples = num_samples
        self.is_train = is_train
        self.config = Config()
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —à—Ä–∏—Ñ—Ç
        self.font_sizes = [16, 18, 20]
        self.fonts = {}
        for size in self.font_sizes:
            try:
                self.fonts[size] = ImageFont.truetype("arial.ttf", size)
            except:
                self.fonts[size] = ImageFont.load_default()
                print(f"‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω—ã–π —à—Ä–∏—Ñ—Ç –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ {size}")

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        # –°–ª—É—á–∞–π–Ω—ã–π —Å–∏–º–≤–æ–ª
        char = random.choice(self.config.chars)
        font_size = random.choice(self.font_sizes)
        font = self.fonts[font_size]
        
        # –°–æ–∑–¥–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img = Image.new('L', (self.config.img_size, self.config.img_size), 0)
        draw = ImageDraw.Draw(img)
        
        # –ü—Ä–æ—Å—Ç–æ–µ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
        text_x = (self.config.img_size - 10) // 2
        text_y = (self.config.img_size - 10) // 2
        
        draw.text((text_x, text_y), char, fill=255, font=font)
        
        # –ü—Ä–æ—Å—Ç—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
        if self.is_train and random.random() > 0.5:
            # –°–ª—É—á–∞–π–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ
            x_shift = random.randint(-2, 2)
            y_shift = random.randint(-2, 2)
            new_img = Image.new('L', img.size, 0)
            new_img.paste(img, (x_shift, y_shift))
            img = new_img
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
        img_tensor = transforms.ToTensor()(img)
        img_tensor = transforms.Normalize((0.5,), (0.5,))(img_tensor)
        
        label = self.config.chars.index(char)
        return img_tensor, label

# –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å
class SimpleCharRecognizer(nn.Module):
    def __init__(self, num_classes):
        super(SimpleCharRecognizer, self).__init__()
        
        self.features = nn.Sequential(
            # 24x24 -> 12x12
            nn.Conv2d(1, 16, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            # 12x12 -> 6x6
            nn.Conv2d(16, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            # 6x6 -> 3x3
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(3),
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(64 * 3 * 3, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

def train_simple_model():
    print("üöÄ –ó–ê–ü–£–°–ö –ü–†–û–°–¢–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø 24x24")
    
    config = Config()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üì± –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    print("üìÅ –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
    train_dataset = SimpleCharsDataset(num_samples=5000, is_train=True)
    test_dataset = SimpleCharsDataset(num_samples=1000, is_train=False)
    
    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)
    
    # –ú–æ–¥–µ–ª—å
    model = SimpleCharRecognizer(config.num_classes).to(device)
    
    # –°—á–∏—Ç–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    total_params = sum(p.numel() for p in model.parameters())
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {total_params:,}")
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)
    criterion = nn.CrossEntropyLoss()
    
    # –û–±—É—á–µ–Ω–∏–µ
    print(f"\nüéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {config.epochs} —ç–ø–æ—Ö...")
    print(f"üì¶ Batch size: {config.batch_size}")
    print(f"üìö –û–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–º–µ—Ä—ã: {len(train_dataset)}")
    print(f"üß™ –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã: {len(test_dataset)}")
    
    train_losses = []
    test_accuracies = []
    best_accuracy = 0
    
    for epoch in range(config.epochs):
        # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
        model.train()
        total_loss = 0
        batches = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            batches += 1
            
            if batch_idx % 10 == 0:
                print(f'    Batch {batch_idx}, Loss: {loss.item():.4f}')
        
        avg_loss = total_loss / batches
        train_losses.append(avg_loss)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                outputs = model(data)
                _, predicted = torch.max(outputs.data, 1)
                total += target.size(0)
                correct += (predicted == target).sum().item()
        
        accuracy = 100 * correct / total
        test_accuracies.append(accuracy)
        
        print(f'‚úÖ –≠–ø–æ—Ö–∞ {epoch+1}/{config.epochs}:')
        print(f'   üìâ Loss: {avg_loss:.4f}')
        print(f'   üìà Accuracy: {accuracy:.2f}%')
        print(f'   ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: {correct}/{total}')

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    torch.save({
        'epoch': config.epochs,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'accuracy': accuracy,
        'loss': avg_loss,
        'config': config.__dict__
    }, 'final_char_model_24x24.pth')
    print(f"üíæ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫: final_char_model_24x24.pth")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    print(f"\nüìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
    for file in os.listdir('.'):
        if file.endswith('.pth') and '24x24' in file:
            file_size = os.path.getsize(file) // 1024
            print(f"   - {file} ({file_size} KB)")
    
    # –ü—Ä–æ—Å—Ç–æ–π –≥—Ä–∞—Ñ–∏–∫
    plt.figure(figsize=(10, 4))
    
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, 'b-')
    plt.title('–ü–æ—Ç–µ—Ä–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏')
    plt.xlabel('–≠–ø–æ—Ö–∞')
    plt.ylabel('Loss')
    plt.grid(True)
    
    plt.subplot(1, 2, 2)
    plt.plot(test_accuracies, 'g-')
    plt.title('–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ')
    plt.xlabel('–≠–ø–æ—Ö–∞')
    plt.ylabel('Accuracy (%)')
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig('simple_training_results.png', dpi=100)
    plt.show()
    
    return best_accuracy

def test_model_quick():
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏"""
    print("\nüß™ –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –ú–û–î–ï–õ–ò")
    config = Config()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞
    model = SimpleCharRecognizer(config.num_classes).to(device)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_dataset = SimpleCharsDataset(num_samples=100, is_train=False)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            outputs = model(data)
            _, predicted = torch.max(outputs.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    
    accuracy = 100 * correct / total
    print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ 100 –ø—Ä–∏–º–µ—Ä–∞—Ö: {accuracy:.2f}%")
    print(f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: {correct}/{total}")
    
    return accuracy

def check_existing_models():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏"""
    print("üîç –ü–æ–∏—Å–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π...")
    model_files = []
    
    for file in os.listdir('.'):
        if file.endswith('.pth'):
            model_files.append(file)
            file_size = os.path.getsize(file) // 1024
            print(f"   üìÅ {file} ({file_size} KB)")
    
    return model_files

if __name__ == "__main__":
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Å–µ–º–µ–Ω–∞ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    torch.manual_seed(42)
    random.seed(42)
    np.random.seed(42)
    
    try:
        print("=" * 50)
        print("üéØ –ü–†–û–°–¢–û–ô –†–ê–°–ü–û–ó–ù–ê–¢–ï–õ–¨ –°–ò–ú–í–û–õ–û–í 24x24")
        print("=" * 50)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏
        existing_models = check_existing_models()
        
        if existing_models:
            print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(existing_models)} –º–æ–¥–µ–ª–µ–π")
            response = input("üîÑ –•–æ—Ç–∏—Ç–µ –æ–±—É—á–∏—Ç—å –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å? (y/n): ")
            if response.lower() != 'y':
                print("üö´ –û–±—É—á–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ")
                exit()
        
        # –°–Ω–∞—á–∞–ª–∞ –±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
        test_accuracy = test_model_quick()
        
        print("\nüîß –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
        final_accuracy = train_simple_model()
        
        print(f"\nüéä –§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {final_accuracy:.2f}%")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è —Ç–µ—Å—Ç–µ—Ä–∞
        print(f"\nüìã –ò–ù–°–¢–†–£–ö–¶–ò–Ø:")
        print(f"1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç–µ—Ä: python interactive_symbol_tester_24x24_fixed.py")
        print(f"2. –û–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
        print(f"3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–∞–π–¥–µ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤")
        
    except Exception as e:
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
