# reliable_enhanced_training.py
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import os
import urllib.request
import gzip
import shutil
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
def ensure_mnist_data():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ MNIST –µ—Å–ª–∏ –Ω—É–∂–Ω–æ"""
    data_path = './data/MNIST/raw'
    os.makedirs(data_path, exist_ok=True)
    
    files = [
        'train-images-idx3-ubyte.gz',
        'train-labels-idx1-ubyte.gz', 
        't10k-images-idx3-ubyte.gz',
        't10k-labels-idx1-ubyte.gz'
    ]
    
    urls = [
        'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',
        'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',
        'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',
        'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'
    ]
    
    all_files_exist = all(os.path.exists(os.path.join(data_path, f)) for f in files)
    
    if not all_files_exist:
        print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ MNIST...")
        for url, filename in zip(urls, files):
            filepath = os.path.join(data_path, filename)
            if not os.path.exists(filepath):
                print(f"–°–∫–∞—á–∏–≤–∞–µ–º {filename}...")
                try:
                    urllib.request.urlretrieve(url, filepath)
                    with gzip.open(filepath, 'rb') as f_in:
                        with open(filepath.replace('.gz', ''), 'wb') as f_out:
                            shutil.copyfileobj(f_in, f_out)
                    print(f"‚úÖ {filename} –∑–∞–≥—Ä—É–∂–µ–Ω –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filename}: {e}")
    else:
        print("‚úÖ –î–∞–Ω–Ω—ã–µ MNIST —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

# –£–ª—É—á—à–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –≤–Ω–∏–º–∞–Ω–∏–µ–º –∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã–º —Ü–∏—Ñ—Ä–∞–º
class EnhancedDigitRecognizer(nn.Module):
    def __init__(self):
        super(EnhancedDigitRecognizer, self).__init__()
        
        # –ü–µ—Ä–≤—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        
        # –í—Ç–æ—Ä–æ–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        
        # –¢—Ä–µ—Ç–∏–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)
        
        # –ß–µ—Ç–≤–µ—Ä—Ç—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫ –¥–ª—è –ª—É—á—à–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)
        self.bn4 = nn.BatchNorm2d(256)
        
        self.pool = nn.MaxPool2d(2, 2)
        self.global_pool = nn.AdaptiveAvgPool2d((4, 4))
        self.dropout1 = nn.Dropout(0.3)
        self.dropout2 = nn.Dropout(0.5)
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏ —Å –±–æ–ª—å—à–µ–π –µ–º–∫–æ—Å—Ç—å—é
        self.fc1 = nn.Linear(256 * 4 * 4, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 10)

    def forward(self, x):
        # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.pool(x)
        
        # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫
        x = F.relu(self.bn2(self.conv2(x)))
        x = self.pool(x)
        x = self.dropout1(x)
        
        # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫
        x = F.relu(self.bn3(self.conv3(x)))
        x = self.pool(x)
        x = self.dropout1(x)
        
        # –ß–µ—Ç–≤–µ—Ä—Ç—ã–π –±–ª–æ–∫
        x = F.relu(self.bn4(self.conv4(x)))
        x = self.global_pool(x)
        x = self.dropout1(x)
        
        # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
        x = x.view(-1, 256 * 4 * 4)
        x = F.relu(self.fc1(x))
        x = self.dropout2(x)
        x = F.relu(self.fc2(x))
        x = self.dropout2(x)
        x = self.fc3(x)
        
        return x

# –£–ª—É—á—à–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ü–∏—Ñ—Ä—ã
class AdvancedAugmentation:
    def __init__(self):
        self.affine_transform = transforms.RandomAffine(
            degrees=10,  # –£–º–µ–Ω—å—à–∏–ª –≤—Ä–∞—â–µ–Ω–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏–∏ —Ü–∏—Ñ—Ä
            translate=(0.08, 0.08),  # –£–º–µ–Ω—å—à–∏–ª —Å–º–µ—â–µ–Ω–∏–µ
            scale=(0.9, 1.1),  # –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            shear=8,  # –£–º–µ–Ω—å—à–∏–ª –Ω–∞–∫–ª–æ–Ω
            fill=0
        )
    
    def __call__(self, img):
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—Ñ—Ñ–∏–Ω–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
        img = self.affine_transform(img)
        
        # –°–ª—É—á–∞–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏ (30% chance) - —Ä–µ–∂–µ
        if np.random.random() > 0.7:
            factor = np.random.uniform(0.8, 1.2)  # –ë–æ–ª–µ–µ —É–∑–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω
            enhancer = ImageEnhance.Brightness(img)
            img = enhancer.enhance(factor)
        
        # –°–ª—É—á–∞–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ (30% chance)
        if np.random.random() > 0.7:
            factor = np.random.uniform(0.8, 1.2)
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(factor)
        
        # –°–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–º—ã—Ç–∏–µ (10% chance) - —Ä–µ–∂–µ
        if np.random.random() > 0.9:
            img = img.filter(ImageFilter.GaussianBlur(radius=0.5))  # –ú–µ–Ω—å—à–µ —Ä–∞–∑–º—ã—Ç–∏–µ
            
        # –°–ª—É—á–∞–π–Ω–∞—è —ç—Ä–æ–∑–∏—è/–¥–∏–ª–∞—Ç–∞—Ü–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É 3 –∏ 9
        if np.random.random() > 0.8:
            if np.random.random() > 0.5:
                img = img.filter(ImageFilter.MinFilter(3))  # –≠—Ä–æ–∑–∏—è
            else:
                img = img.filter(ImageFilter.MaxFilter(3))  # –î–∏–ª–∞—Ç–∞—Ü–∏—è
        
        return img

# –ö–ª–∞—Å—Å—ã –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–º–∏ –¥–ª—è multiprocessing)
class TrainTransform:
    def __init__(self):
        self.augmentation = AdvancedAugmentation()
        self.base_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
    
    def __call__(self, img):
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 80%
        if np.random.random() > 0.2:
            img = self.augmentation(img)
        img = self.base_transform(img)
        return img

class TestTransform:
    def __init__(self):
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.1307,), (0.3081,))
        ])
    
    def __call__(self, img):
        return self.transform(img)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫ –º–µ–∂–¥—É 3 –∏ 9
def analyze_3_9_confusion(model, test_loader, device):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç confusion –º–µ–∂–¥—É 3 –∏ 9"""
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            outputs = model(data)
            _, predicted = torch.max(outputs, 1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
    
    # Confusion matrix
    cm = confusion_matrix(all_targets, all_preds)
    
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    
    # –û—Å–æ–±—ã–π —Ñ–æ–∫—É—Å –Ω–∞ 3 –∏ 9
    confusion_3_9 = cm[3, 9] + cm[9, 3]
    total_3_9 = cm[3].sum() + cm[9].sum() - cm[3, 3] - cm[9, 9]
    confusion_rate = confusion_3_9 / total_3_9 if total_3_9 > 0 else 0
    
    plt.subplot(1, 2, 2)
    classes = ['3-3', '3-9', '9-3', '9-9']
    values = [cm[3, 3], cm[3, 9], cm[9, 3], cm[9, 9]]
    colors = ['green', 'red', 'red', 'green']
    
    bars = plt.bar(classes, values, color=colors)
    plt.title(f'Confusion 3-9: {confusion_rate:.2%}')
    plt.ylabel('Count')
    
    for bar, value in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), 
                f'{value}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('3_9_confusion_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑ confusion 3-9:")
    print(f"   3 –æ—à–∏–±–æ—á–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã –∫–∞–∫ 9: {cm[3, 9]}")
    print(f"   9 –æ—à–∏–±–æ—á–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã –∫–∞–∫ 3: {cm[9, 3]}")
    print(f"   –û–±—â–∞—è –æ—à–∏–±–∫–∞ –º–µ–∂–¥—É 3 –∏ 9: {confusion_3_9}")
    print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫: {confusion_rate:.2%}")
    
    return confusion_rate

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
def visualize_problem_cases(model, test_dataset, device, num_examples=10):
    """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä—ã, –≥–¥–µ –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è –º–µ–∂–¥—É 3 –∏ 9"""
    model.eval()
    problematic_examples = []
    
    with torch.no_grad():
        for i in range(len(test_dataset)):
            if len(problematic_examples) >= num_examples * 2:
                break
                
            img, target = test_dataset[i]
            if target not in [3, 9]:
                continue
                
            output = model(img.unsqueeze(0).to(device))
            pred = output.argmax(dim=1).item()
            
            if pred != target and pred in [3, 9]:
                problematic_examples.append((img, target, pred))
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    if problematic_examples:
        plt.figure(figsize=(15, 6))
        for i, (img, target, pred) in enumerate(problematic_examples[:num_examples]):
            plt.subplot(2, 5, i+1)
            plt.imshow(img.squeeze(), cmap='gray')
            plt.title(f'True: {target}, Pred: {pred}')
            plt.axis('off')
        
        plt.tight_layout()
        plt.savefig('problematic_3_9_examples.png', dpi=300, bbox_inches='tight')
        plt.show()

def train_enhanced_model():
    ensure_mnist_data()
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üöÄ –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {device}")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
    train_transform = TrainTransform()
    test_transform = TestTransform()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    try:
        print("üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
        train_dataset = torchvision.datasets.MNIST(
            root='./data', 
            train=True, 
            download=True,
            transform=train_transform
        )
        
        print("üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")
        test_dataset = torchvision.datasets.MNIST(
            root='./data', 
            train=False, 
            download=True,
            transform=test_transform
        )
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return 0, 0
    
    # DataLoader - —É–±–∏—Ä–∞–µ–º pin_memory –∏ num_workers –¥–ª—è Windows
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)
    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=0)
    
    # –ú–æ–¥–µ–ª—å
    model = EnhancedDigitRecognizer().to(device)
    
    # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    total_params = sum(p.numel() for p in model.parameters())
    print(f"üìê –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
    print(f"   - 4 —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –±–ª–æ–∫–∞ —Å BatchNorm")
    print(f"   - Global Average Pooling")
    print(f"   - –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è")
    print(f"   - –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
    
    # –£–ª—É—á—à–µ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label smoothing –¥–ª—è –ª—É—á—à–µ–π –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
    
    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
    scheduler = optim.lr_scheduler.OneCycleLR(
        optimizer, 
        max_lr=0.01,
        epochs=25,
        steps_per_epoch=len(train_loader),
        pct_start=0.3
    )
    
    # –û–±—É—á–µ–Ω–∏–µ
    train_losses = []
    test_accuracies = []
    best_accuracy = 0
    
    print("\nüéØ –ù–∞—á–∏–Ω–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ 3 –∏ 9...")
    print("–£–ª—É—á—à–µ–Ω–∏—è –≤ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:")
    print("   - –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è")
    print("   - –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–∏–π")
    print("   - Label smoothing –¥–ª—è –ª—É—á—à–µ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏")
    print("   - OneCycle LR scheduling")
    
    for epoch in range(25):  # –£–≤–µ–ª–∏—á–∏–ª –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
        # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
        model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()
            scheduler.step()
            
            total_loss += loss.item()
            
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
            
            if batch_idx % 100 == 0:
                current_lr = scheduler.get_last_lr()[0]
                print(f'–≠–ø–æ—Ö–∞ {epoch+1}/25 [{batch_idx * len(data)}/{len(train_loader.dataset)}] '
                      f'Loss: {loss.item():.6f}, LR: {current_lr:.6f}')
        
        train_accuracy = 100 * correct / total
        avg_loss = total_loss / len(train_loader)
        train_losses.append(avg_loss)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        test_correct = 0
        test_total = 0
        
        with torch.no_grad():
            for data, target in test_loader:
                data, target = data.to(device), target.to(device)
                outputs = model(data)
                _, predicted = torch.max(outputs.data, 1)
                test_total += target.size(0)
                test_correct += (predicted == target).sum().item()
        
        test_accuracy = 100 * test_correct / test_total
        test_accuracies.append(test_accuracy)
        
        current_lr = scheduler.get_last_lr()[0]
        
        print(f'–≠–ø–æ—Ö–∞ {epoch+1} –∑–∞–≤–µ—Ä—à–µ–Ω–∞:')
        print(f'  Train Loss: {avg_loss:.4f}, Train Acc: {train_accuracy:.2f}%')
        print(f'  Test Accuracy: {test_accuracy:.2f}%')
        print(f'  Learning Rate: {current_lr:.6f}')
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        if test_accuracy > best_accuracy:
            best_accuracy = test_accuracy
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'test_accuracy': test_accuracy,
                'epoch': epoch,
            }, 'enhanced_digit_model.pth')
            print(f'  üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {test_accuracy:.2f}%')
    
    print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"üéØ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {best_accuracy:.2f}%")
    
    # –ê–Ω–∞–ª–∏–∑ confusion –º–µ–∂–¥—É 3 –∏ 9
    print("\nüîç –ü—Ä–æ–≤–æ–¥–∏–º –∞–Ω–∞–ª–∏–∑ confusion –º–µ–∂–¥—É 3 –∏ 9...")
    confusion_rate = analyze_3_9_confusion(model, test_loader, device)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
    print("\nüìä –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã...")
    visualize_problem_cases(model, test_dataset, device)
    
    # –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(train_losses)
    plt.title('–ü–æ—Ç–µ—Ä–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏')
    plt.xlabel('–≠–ø–æ—Ö–∞')
    plt.ylabel('Loss')
    plt.grid(True)
    
    plt.subplot(1, 2, 2)
    plt.plot(test_accuracies)
    plt.title('–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö')
    plt.xlabel('–≠–ø–æ—Ö–∞')
    plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å (%)')
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig('enhanced_training_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    if confusion_rate < 0.01:
        print("üéâ –û—Ç–ª–∏—á–Ω–æ! –ü—Ä–æ–±–ª–µ–º–∞ 3-9 –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Ä–µ—à–µ–Ω–∞!")
    elif confusion_rate < 0.03:
        print("üëç –•–æ—Ä–æ—à–æ! Confusion –º–µ–∂–¥—É 3 –∏ 9 –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–º–µ–Ω—å—à–∏–ª—Å—è!")
    elif confusion_rate < 0.05:
        print("üí™ –ù–µ–ø–ª–æ—Ö–æ, –Ω–æ –µ—Å—Ç—å –∫—É–¥–∞ —É–ª—É—á—à–∞—Ç—å.")
    else:
        print("üîß –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–∞–¥ –ø—Ä–æ–±–ª–µ–º–æ–π 3-9.")
    
    return best_accuracy, confusion_rate

if __name__ == "__main__":
    accuracy, confusion_rate = train_enhanced_model()
